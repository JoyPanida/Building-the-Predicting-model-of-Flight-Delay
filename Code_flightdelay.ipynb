{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## อ่านไฟล์ my_new_flights.csv คือไฟล์ข้อมูลที่เพิ่มคอลัมน์ last_dep_delay, last_arr_delay แล้ว"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/my-new-flights/my_new_flights.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ทำการสุ่มตัวอย่างข้อมูลมา 1%(5หมื่นแถว) จากข้อมูลทั้งหมด 5ล้านแถว เนื่องจาก kernel มีปัญหาล้มเหลวบ่อยเนื่องจากฝึกฝนโมเดลกับข้อมูลจำนวนมาก\n### <font color=blue>ได้ทำการทดสอบข้อมูลทั้งหมด6ขนาดแล้วคือ 1%, 5%, 10%, 20%, 50%, 100%,  </font> พบว่าไม่มีผลกับการสร้างโมเดลเนื่องจากข้อมูลคือเที่ยวบินที่เริ่มตั้งแต่วันที่ 1 ม.ค. 2015 ถึง 31 ธ.ค. 2015 ซึ่งเป็นข้อมูลที่มีการเรียงลำดับมาเรียบร้อยแล้ว ข้อมูลที่สุ่มตัวอย่างในแต่ละขนาดจึงมีจำนวนในแต่ละเดือนเท่าๆกัน \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.sample(frac=0.01, replace=True, random_state=1)  # 50k","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"แสดงตัวอย่างข้อมูล "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"แสดงขนาดข้อมูล"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### เนื่องจากข้อมูลที่ใช้จะเป็นข้อมูลที่สามารถได้รับตั้งแต่เครื่องบินเริ่มเก็บล้อและลอยตัวออกจากรันเวย์ ข้อมูลต่างๆที่ได้รับหลังจากนี้จะทำการลบออกจากชุดข้อมูล\n['CANCELLATION_REASON',\n'CANCELLED',\n'ARRIVAL_TIME',\n'DIVERTED',\n'ELAPSED_TIME',\n'AIR_TIME',\n'WHEELS_ON',\n'TAXI_IN',\n'AIR_SYSTEM_DELAY',\n'SECURITY_DELAY',\n'AIRLINE_DELAY',\n'LATE_AIRCRAFT_DELAY',\n'WEATHER_DELAY']\n<font color=red>ชุดคอลัมน์ข้างบนคือข้อมูลที่จะได้รับตั้งแต่เครื่องเริ่มลอยตัวจากรันเวย์จนถึงท่าอากาศยานปลายทางซึ่งเป็นข้อมูลที่ไม่สามารถใช้ได้ในการสร้างโมเดลได้ เพราะจุดมุ่งหมายของโปรเจคนี้คือการทำนายตอนที่เครื่องบินเก็บล้อเท่านั้น</font>\n<br><br><br><br>\n['ORIGIN_AIRPORT'\n'DESTINATION_AIRPORT' \n'TAIL_NUMBER'\n'FLIGHT_NUMBER']\n<font color=red>คือชุดคอลัมน์ข้อมูลที่จะเป็นแบบคลาสซึ่งในแต่ละคอลัมน์มีประเภทข้อมูลที่หลากหลายและไม่สามารถนำไปทำ one-hot เพื่อใช้เป็นข้อมูลในการสร้างโมเดลได้</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# เนื่องจากไม่ได้ใช้ข้อมูล cancelled และข้อมูลมีมากไม่เหมาะการทำ onehot \ndf = df.drop(columns=['CANCELLATION_REASON', 'CANCELLED','ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', \n                      'TAIL_NUMBER', 'ARRIVAL_TIME', 'FLIGHT_NUMBER','DIVERTED',\n                      'ELAPSED_TIME','AIR_TIME','WHEELS_ON','TAXI_IN','AIR_SYSTEM_DELAY', \n                      'SECURITY_DELAY','AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ทำการลบข้อมูลที่เป็น missing value และรีเซ็ตค่าของ index ใหม่เพราะว่าข้อมูลที่สุ่มมา indexที่ไม่เรียงกันจะทำให้เกิด error ในการทำ EDA หรือการเพิ่มคอลัมน์ใหม่"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna()\ndf= df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ขนาดของข้อมูลหลังจากลบคอลัมน์ที่ไม่ใช้กับ การลบ missing value"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ทำการเปลี่ยนค่าคอลัมน์(ARRIVAL_DELAY)ที่บอกว่าเที่ยวบินล่าช้ากี่นาที เป็นการข้อมูลคอลัมน์(FLIGHT_DELAY)ใหม่ที่บอกว่าล่าช้าหรือไม่ล่าช้า โดย 0 คือ ไม่ล่าช้า และ 1 คือ เกิดความล่าช้า"},{"metadata":{"trusted":true},"cell_type":"code","source":"#เปลี่ยนคอลัมน์ให้เป็น classification\ndf['FLIGHT_DELAY'] = np.where(df['ARRIVAL_DELAY'] > 0, 1,0)\ndel df['ARRIVAL_DELAY']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"แสดงจำนวนเที่ยวบินที่เกิดความล่าช้า และไม่เกิดความล่าช้า"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('FLIGHT_DELAY').size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ทำการสร้างกราฟตรวจสอบว่า ในแต่ละช่วงของเดือนมีเที่ยวบินที่เกิดความล่าช้าที่สุดในช่วงไหนบ้าง โดยแบ่งให้ ตั้งแต่วันที่ 1 ถึง 10 เป็นต้นเดือน 11 ถึง 20 เป็นกลางเดือน 20ขึ้นไปให้เป็นปลายเดือน โดยใช้ค่าของ day_tmp(วันของเดือน)ที่แบ่งclass เป็น 3 ช่วง พบว่าไม่มีความแตกต่างกันอย่างมีนัยสำคัญ  "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Day of month\ndf2 = df[df['FLIGHT_DELAY'] ==1]\n\nday_tmp = []\nfor n in  df2['DAY'].tolist() :\n    if n < 11 :\n        day_tmp.append(\"begin\")\n    elif n < 21:\n        day_tmp.append(\"middle\")\n    else:\n         day_tmp.append(\"end\")\n\ndf2['DAY_CLASS'] = day_tmp\ndf2['DAY_CLASS'].value_counts()   \n\nplt.bar(df2['DAY_CLASS'].value_counts().index.tolist(),\ndf2['DAY_CLASS'].value_counts().values.tolist(),\ncolor=['blue'])\nplt.title(\"Class label distribution\")\nplt.ylabel('Frequency')\nplt.xlabel('Class label')\nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ทำการสร้างกราฟตรวจสอบว่าในแต่ละวันของสัปดาห์มีจำนวนเที่ยวบินที่เกิดความล่าช้าเท่าใด"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Day of week\nplt.bar(df2['DAY_OF_WEEK'].value_counts().index.tolist(),\ndf2['DAY_OF_WEEK'].value_counts().values.tolist(),\ncolor=['blue'])\nplt.title(\"Class label distribution\")\nplt.ylabel('Frequency')\nplt.xlabel('Class label')\nplt.tight_layout()\n\n# 3 class 4,5= d_high, 1,2,3,7=d_medium  6= d_low","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### แบ่งระดับการเกิดความล่าช้าเป็น 3 ระดับ อิงจากกราฟด้านบน โดยจะนำมาสร้างเป็นคอลัมน์ใหม่ชื่อ day_delay\n\n<font color=red>3 class <br> d_high=[4,5]  d_medium=[1,2,3,7]   d_low=[6]<font/>"},{"metadata":{"trusted":true},"cell_type":"code","source":"day_tmp = []\nfor n in  df['DAY_OF_WEEK'].tolist() :\n    if n in [4,5] :\n        day_tmp.append('d_high')\n    elif n in [1, 2, 3, 7]  :\n        day_tmp.append('d_medium')\n    else: \n        day_tmp.append('d_low')\n    \n\ndf['day_delay'] = day_tmp\ndf['day_delay'].value_counts()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ทำการสร้างกราฟตรวจสอบว่าในแต่ละเดือนมีจำนวนเที่ยวบินที่เกิดความล่าช้าเท่าใด"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(df2['MONTH'].value_counts().index.tolist(),\ndf2['MONTH'].value_counts().values.tolist(),\ncolor=['blue'])\nplt.title(\"Class label distribution\")\nplt.ylabel('Frequency')\nplt.xlabel('Class label')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### แบ่งระดับการเกิดความล่าช้าเป็น 3 ระดับ อิงจากกราฟด้านบน โดยจะนำมาสร้างเป็นคอลัมน์ใหม่ชื่อ month_class\n\n<font color=red>3 class <br> M_high=[1,3,6,7,8,12]  M_medium=[2,4,5]   M_low=[9,10,11]<font/>"},{"metadata":{"trusted":true},"cell_type":"code","source":"month_tmp = []\nfor n in  df['MONTH'].tolist() :\n    if n in [9,10,11] :\n        month_tmp.append('M_low')\n    elif n in [2,4,5] :\n        month_tmp.append('M_medium')\n    else: \n        month_tmp.append('M_high')\n        \ndf['month_class'] = month_tmp\ndf['month_class'].value_counts()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ทำการสร้างกราฟตรวจสอบว่ามีเที่ยวบินที่ตามกำหนดการต้องออกเดินทางในแต่ละชั่วโมงมีจำนวนเที่ยวบินที่เกิดความล่าช้าเท่าใด"},{"metadata":{"trusted":true},"cell_type":"code","source":"# SCHEDULED_DEPARTURE\ndef time_to_string(n):\n    if n  < 100 :\n        return('0')\n    elif n < 200 :\n        return('1')\n    elif n < 300 :\n        return('2')\n    elif n < 400 :\n        return('3')    \n    elif n < 500 :\n        return('4')        \n    elif n < 600 :\n        return('5')\n    elif n < 700 :\n        return('6')\n    elif n < 800 :\n        return('7')\n    elif n < 900 :\n        return('8')    \n    elif n < 1000 :\n        return('9')\n    elif n < 1100 :\n        return('10')\n    elif n < 1200 :\n        return('11')\n    elif n < 1300 :\n        return('12')\n    elif n < 1400 :\n        return('13')\n    elif n < 1500 :\n        return('14')    \n    elif n < 1600 :\n        return('15')        \n    elif n < 1700 :\n        return('16')\n    elif n < 1800 :\n        return('17')\n    elif n < 1900 :\n        return('18')\n    elif n < 2000 :\n        return('19')    \n    elif n < 2100 :\n        return('20')\n    elif n < 2200 :\n        return('21')\n    elif n < 2300 :\n        return('22')\n    else: \n        return('23')\n    \ntime_tmp = []\nfor n in  df2['SCHEDULED_DEPARTURE'].tolist() :\n        time_tmp.append(time_to_string(n))\n\n        \ndf2['time_tmp'] = time_tmp\n\ndf2['time_tmp'].value_counts()   \n\nplt.bar(df2['time_tmp'].value_counts().index.tolist(),\ndf2['time_tmp'].value_counts().values.tolist(),\ncolor=['blue'])\nplt.title(\"Class label distribution\")\nplt.ylabel('Frequency')\nplt.xlabel('Class label')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### แบ่งระดับการเกิดความล่าช้าเป็น 4 ระดับ อิงจากกราฟด้านบน โดยจะนำมาสร้างเป็นคอลัมน์ใหม่ชื่อ hour_class\n\n<font color=red>4 class <br>H_high=[17,15,19,18,16,13]  H_medium=[14,12,11,10]   H_low=[8,20,9,7,6,21]  H_lowest=[22,5,23,0,1,4,3,2]<font/>"},{"metadata":{"trusted":true},"cell_type":"code","source":"hour_tmp = []\nfor n in  df['SCHEDULED_DEPARTURE'].tolist() :\n    n = time_to_string(n)\n    if n in ['17','15', '19', '18', '16', '13'] : \n        hour_tmp.append('H_high')\n    elif n in ['14', '12', '11', '10'] :\n        hour_tmp.append('H_medium')\n    elif n in ['8', '20', '9', '7','6', '21'] :\n        hour_tmp.append('H_low')\n    else: \n        hour_tmp.append('H_lowest')\n        \ndf['hour_class'] = hour_tmp\ndf['hour_class'].value_counts()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### clean data ก่อนทำ OnehotEncoding\nดรอป year, month, day, day of week, airline  เพราะว่าเราทำเป็นclass แล้ว"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(columns=['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ตรวจสอบประเภทของข้อมูล"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ทำ object type ให้เป็นอยู่ในรูปแบบ onehot"},{"metadata":{"trusted":true},"cell_type":"code","source":"from  sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(categories='auto')\nfeature_arr = ohe.fit_transform(df[['month_class', 'hour_class','day_delay']]).toarray() # list of one-hot-encoder\n#print(feature_arr)\nfeature_labels = ohe.categories_  # list of new column name  \n#print(feature_labels)\n#feature_labels = np.array(feature_labels).ravel() # no effect\nfeature_labels =  np.concatenate((feature_labels), axis=None)\n#print(feature_labels)\nfeatures = pd.DataFrame(feature_arr, columns=feature_labels)\ndf = pd.concat([features,df], axis=1, sort=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ตรวจสอบความสัมพันะ์ของข้อมูลโดย coreration heat map"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n%matplotlib inline\n\n# calculate the correlation matrix\ncorr = df.corr()\n\n# plot the heatmap\nsns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### เปลี่ยนคอลัมน์ที่เป็นตัวเลขทุกคอลัมน์ให้อยู่ในรูปแบบ numeric เพื่อใช้ในการตรวจสอบ outlier "},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_cols = ['DEPARTURE_DELAY',\n                'TAXI_OUT','WHEELS_OFF','SCHEDULED_TIME',\n                'DISTANCE','last_dep_delay','last_arr_delay', 'SCHEDULED_DEPARTURE','DEPARTURE_TIME', 'SCHEDULED_ARRIVAL']\n\nfor col in numeric_cols:\n    df[col] = pd.to_numeric(df[col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ทำการแสดงค่าของ outlier ทุกคอลัมน์ที่เป็นตัวเลข แต่คอมเมนต์เอาไว้เนื่องจากข้อมูลที่แสดงยาวเกินไป"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in numeric_cols:\n  #  print(\"Column name:  \" + col)\n    q1= df[col].quantile(0.25)\n    q3 = df[col].quantile(0.75)\n    iqr = q3-q1\n    lower_bound = q1 -(1.5 * iqr)\n    upper_bound = q3 +(1.5 * iqr)\n #   print('q1 = {}'.format(q1))\n #   print('q3 = {}'.format(q3))\n #   print('iqr = {}'.format(iqr))\n#     print('lower bound = {}, upper bound = {}'.format(lower_bound, upper_bound))\n    outlier_row_indice = df[(df[col] < lower_bound) | (df[col]>upper_bound)].index\n#     print('number of outliers = {}'.format(len(outlier_row_indice)))\n#     print('indices of outliers = ', outlier_row_indice.to_list())\n#    print(\"######################################\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### แสดงค่าของ outlier ทุกคอลัมน์บนกราฟ"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(numeric_cols)\nfig, axes = plt.subplots(figsize=(18, 10), nrows=3, ncols=3, squeeze=0)\ni=0\nfor ax, col in zip(axes.reshape(-1), numeric_cols):\n      ax.boxplot(df[col], labels=[col], sym='k.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### เตรียมข้อมูลสำหรับเป็น outputที่ใช้ในการฝึกฝนและทดสอบโมเดล และทำการลบออกจากชุดข้อมูลพร้อมกับลบคอลัมน์ที่ได้ทำการ one-hotไปแล้วออก"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['FLIGHT_DELAY'].tolist()\n\ndel df['FLIGHT_DELAY']\ndel df['month_class']\ndel df['hour_class']\ndel df['day_delay']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ตรวจสอบค่าทุกคอลัมน์ถ้าเป็นตัวเลขหมดแล้วแสดงว่าพร้อมที่จะนำเข้าไปใช้ในการฝึกฝนโมเดล"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### เตรียมข้อมูลสำหรับเป็น input ที่ใช้ในการฝึกฝนและทดสอบโมเดล"},{"metadata":{"trusted":true},"cell_type":"code","source":"#df = pd.concat([df,features], axis=1)\nX = df.iloc[:, :].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## แบ่งข้อมูลทั้งหมดเป็น 3 ชุด คือ 1.train(64%) 2.valid(16%) 3.test (20%)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** ทำการ Scaler ข้อมูลก่อนนำไปฝึกฝน**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**การสร้าง model เพื่อทำนายผลลัพธ์ของความ delay โดย DecisionTreeClassifier  **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ทำนายผลของ decisionTree model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**แสดงค่า Accurency precision recall ของ decisionTree **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(\"Performance:\")\nprint(\" >accuracy = \" + str(accuracy))\nprint(\" >precision = \" + str(precision))\nprint(\" >recall = \" + str(recall))\nprint(\" >f1 = \" + str(f1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**หาค่า learning rate ที่ได้ค่าความถูกต้องสูงที่สุดของ GradientBoostingClassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n\nlr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75]\n\nfor learning_rate in lr_list:\n    gb_clf = GradientBoostingClassifier(n_estimators=10, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n    gb_clf.fit(X_train, y_train)\n\n    print(\"Learning rate: \", learning_rate)\n    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**GradientBoostingClassifier** <br>\n**นำค่า learning rate ที่ได้ค่า Accurency สูงสุดมาสร้าง model และประมวลผล**"},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.5, max_features=2, max_depth=2, random_state=0)\ngb_clf2.fit(X_train, y_train)\npredictions = gb_clf2.predict(X_test)\n\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, predictions))\n\nprint(\"Classification Report\")\nprint(classification_report(y_test, predictions))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** ฝึกฝนโมเดลโดย k-Nearest Neighbors (k-NN)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\n#create new a knn model\nknn = KNeighborsClassifier()\n#create a dictionary of all values we want to test for n_neighbors\nparams_knn = {'n_neighbors': np.arange(1, 5)}\n#use gridsearch to test all values for n_neighbors\nknn_gs = GridSearchCV(knn, params_knn, cv=5)\n#fit model to training data\nknn_gs.fit(X_train, y_train)\n\n#save best model\nknn_best = knn_gs.best_estimator_\n#check best n_neigbors value\nprint(knn_gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** ฝึกฝนโมเดลโดย Random Forest **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n#create a new random forest classifier\nrf = RandomForestClassifier()\n#create a dictionary of all values we want to test for n_estimators\nparams_rf = {'n_estimators': [100, 200]}\n#use gridsearch to test all values for n_estimators\nrf_gs = GridSearchCV(rf, params_rf, cv=5)\n#fit model to training data\nrf_gs.fit(X_train, y_train)\n\n#save best model\nrf_best = rf_gs.best_estimator_\n#check best n_estimators value\nprint(rf_gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** ฝึกฝนโมเดลโดย LogisticRegression และใช้ GridSearchCV เพื่อหาพาราเมตเตอร์ที่ได้ค่าความถูกต้องสูงที่สุด **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'penalty':['l2'], # l1 is Lasso, l2 is Ridge\n    'class_weight' : ['dict', 'balanced'],\n    'C': [0.01,0.10,0.25,0.50,0.75,1.0],#np.linspace(0.00002,1,100),\n    'solver' : ['newton-cg', 'lbfgs',  'sag', 'saga']\n}\n\nlr = LogisticRegression()\nlr_gs = GridSearchCV(lr, params, cv=3, verbose=1).fit(X_train, y_train)\n\nprint (\"Best Params\", lr_gs.best_params_)\nprint (\"Best Score\", lr_gs.best_score_)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** นำค่าพาราเมตเตอร์ที่เหมาะสมที่สุดของโมเดล  LogisticRegressionมาทำการฝึกฝน **"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_best = LogisticRegression(C= 0.75, class_weight = 'dict', penalty = 'l2', solver = 'lbfgs')\nlr_best.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" **แสดงค่า score ของ k-Nearest Neighbors, Random Forest, LogisticRegression **"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('knn: {}'.format(knn_best.score(X_test, y_test)))\nprint('rf: {}'.format(rf_best.score(X_test, y_test)))\nprint('log_reg: {}'.format(lr_best.score(X_test, y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** ฝึกฝนโมเดลโดย SVM **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclf = SVC(gamma='auto')\nclf.fit(X_train, y_train) \nclf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** ทำการใช้เทคนิค Voting Classifier โดยนำ3โมเดล (k-Nearest Neighbors, Random Forest, LogisticRegression) ที่ถูกฝึกฝนเรียบร้อยแล้วมาช่วยกันโหวต  **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n#create a dictionary of our models\nestimators=[('gb', gb_clf2), ('clf', clf), ('log_reg', lr_best)]\n#create our voting classifier, inputting our models\nensemble = VotingClassifier(estimators, voting='hard')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### วัดผลการ voting"},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit model to training data\nensemble.fit(X_train, y_train)\n#test our model on the test data\nensemble.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** ฝึกฝนโมเดลโดย catboost **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\n\nparams = {'loss_function':'Logloss', # objective function\n          'eval_metric':'AUC', # metric\n          'verbose': 200, # output to stdout info about training process every 200 iterations\n          'random_seed': 1\n         }\nclassifier = CatBoostClassifier(**params)\nclassifier.fit(X_train, y_train, # data to train on (required parameters, unless we provide X as a pool object, will be shown below)\n          eval_set=(X_valid, y_valid), # data to validate on\n          use_best_model=True, # True if we don't want to save trees created after iteration with the best validation score\n          plot=True # True for visualization of the training process (it is not shown in a published kernel - try executing this code)\n         );","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### นำโมเดลที่ฝึกฝนแล้วโดย catboost มาทำนายกับข้อมูลทดสอบ"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Test Set results\ny_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### แสดงผลการทำนายในรูปแบบ confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred.round())\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**แสดงค่า Accurency precision recall ของ catboost **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(\"Performance:\")\nprint(\" >accuracy = \" + str(accuracy))\nprint(\" >precision = \" + str(precision))\nprint(\" >recall = \" + str(recall))\nprint(\" >f1 = \" + str(f1))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}